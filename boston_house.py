# -*- coding: utf-8 -*-
"""boston_house.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SvbAiFf8F8i4Oot1gbywLLtDuOqn4b9P
"""

import pandas as pd
df = pd.read_csv('/content/Boston.csv')

print(df.head())
print("----------"*10)
print(df.tail())
print("----------"*10)
print(df.info())
print("----------"*10)
print(df.isnull().sum())
print("----------"*10)
df.describe()

"""**Linear** **Regression**

>trainig the first model as linear regression


"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.metrics import classification_report

X = df.drop('medv',axis =1)
y = df['medv']

X_train, X_test ,y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = LinearRegression()
model.fit(X_train_scaled,y_train)

y_pred = model.predict(X_test_scaled)

r2_lr = r2_score(y_test, y_pred)
print(r2_lr)

from sklearn.metrics import confusion_matrix, classification_report,accuracy_score
import numpy as np

bins = [0, 15, 30, 100]  # 3 categories
labels = ["Low", "Medium", "High"]

y_test_cat = np.digitize(y_test, bins)
y_pred_cat = np.digitize(y_pred, bins)

cm = confusion_matrix(y_test_cat, y_pred_cat)
print("Confusion Matrix:\n", cm)
print("\nClassification Report:\n")
print(classification_report(y_test_cat, y_pred_cat, target_names=labels))
acc_lr = accuracy_score(y_test_cat, y_pred_cat)

"""**Random** **Forest**

> second model is used as random forest
"""

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(random_state=42, n_estimators=200)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
r2_rf = r2_score(y_test, y_pred_rf)
print(r2_rf)

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
bins = [0, 15, 30, 100]
labels = ["Low", "Medium", "High"]
y_test_cat = np.digitize(y_test, bins)
y_pred_cat = np.digitize(y_pred_rf, bins)
confusion_matrix(y_test_cat, y_pred_cat)

cm1 = confusion_matrix(y_test_cat, y_pred_cat)
print("Confusion Matrix:\n", cm1)
print("\nClassification Report:\n")
print(classification_report(y_test_cat, y_pred_cat, target_names=labels))
acc_rf = accuracy_score(y_test_cat, y_pred_cat)

"""**SVM**

> 3 model using SVM


"""

from sklearn.svm import SVR
from sklearn.metrics import r2_score

svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)
svr.fit(X_train_scaled, y_train)

y_pred_sv = svr.predict(X_test_scaled)

r2_svm = r2_score(y_test, y_pred_sv)

print(r2_svm)

bins = [0, 15, 30, 100]
labels = ["Low", "Medium", "High"]
y_test_cat = np.digitize(y_test, bins)
y_pred_cat = np.digitize(y_pred_sv, bins)

cm3 = confusion_matrix(y_test_cat, y_pred_cat)
print("\nConfusion Matrix:\n", cm3)

print("\nClassification Report:\n")
print(classification_report(y_test_cat, y_pred_cat, target_names=labels))
acc_svm = accuracy_score(y_test_cat, y_pred_cat)

"""**Comparsion**"""

import matplotlib.pyplot as plt
import numpy as np

models = ["Linear Regression", "Random Forest", "SVM"]
r2_scores = [r2_lr, r2_rf, r2_svm]
accuracies = [acc_lr, acc_rf, acc_svm]

x = np.arange(len(models))
width = 0.35

plt.figure(figsize=(8,5))
bars1 = plt.bar(x - width/2, r2_scores, width, label="R² Score", color='skyblue')
bars2 = plt.bar(x + width/2, accuracies, width, label="Classification Accuracy", color='orange')

for bar in bars1:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.02, f"{height*100:.1f}%", ha='center', fontsize=10)
for bar in bars2:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height + 0.02, f"{height*100:.1f}%", ha='center', fontsize=10)

plt.xticks(x, models)
plt.ylabel("Score")
plt.title("Model Comparison: R² vs Classification Accuracy")
plt.legend()
plt.ylim(0,1)
plt.show()